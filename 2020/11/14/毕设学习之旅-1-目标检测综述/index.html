<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/polardb.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/polardb.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/polardb.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="QDK1R1zUVUQzV5bHVQblZqnw-dHV6smKnoO0csfEhik">
  <meta name="baidu-site-verification" content="QHwpbaZPVp">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">




<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://gknl.github.io').hostname,
    root: '/',
    scheme: 'Mist',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":true},
    copycode: {"enable":false,"show_result":false,"style":"mac"},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: './public/search.xml',
    motion: {"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="img{text-align: center; margin: 0 auto;width:80%;}  前言 一转眼已经过去半年了，今年最大的愿望已经顺利实现！（有时间再专门开一篇文章专门记录保研之旅）几经波折，总算是定好毕设题目啦！接下来是漫长的学习与实践道路，为了督促学习，开此坑来记录毕设学习全过程。  本文记录了个人对于cv目标检测领域的知识点综述总结【Anchor-free待填坑】">
<meta property="og:type" content="article">
<meta property="og:title" content="毕设学习之旅-1.目标检测综述">
<meta property="og:url" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/index.html">
<meta property="og:site_name" content="钢盔女郎の博客">
<meta property="og:description" content="img{text-align: center; margin: 0 auto;width:80%;}  前言 一转眼已经过去半年了，今年最大的愿望已经顺利实现！（有时间再专门开一篇文章专门记录保研之旅）几经波折，总算是定好毕设题目啦！接下来是漫长的学习与实践道路，为了督促学习，开此坑来记录毕设学习全过程。  本文记录了个人对于cv目标检测领域的知识点综述总结【Anchor-free待填坑】">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-0.png">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-1.png">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-2.png">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-3.png">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-4.png">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-5.png">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-7.png">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-8.png">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-9.png">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-10.png">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-11.png">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-12.png">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-13.png">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-14.png">
<meta property="og:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-15.png">
<meta property="article:published_time" content="2020-11-14T05:43:00.000Z">
<meta property="article:modified_time" content="2020-11-17T14:46:04.222Z">
<meta property="article:author" content="PM">
<meta property="article:tag" content="毕业设计">
<meta property="article:tag" content="目标检测">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-0.png">

<link rel="canonical" href="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>毕设学习之旅-1.目标检测综述 | 钢盔女郎の博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="stylesheet" href="\assets\css\APlayer.min.css" class="aplayer-style-marker">
<script src="\assets\js\APlayer.min.js" class="aplayer-script-marker"></script>
<script src="\assets\js\Meting.min.js" class="meting-script-marker"></script>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">钢盔女郎の博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">PM</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">6</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">4</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">18</span></a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-fw fa-sitemap"></i>站点地图</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://gknl.github.io/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/headImage.jpeg">
      <meta itemprop="name" content="PM">
      <meta itemprop="description" content="菜鸡博客,记录生活">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="钢盔女郎の博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          毕设学习之旅-1.目标检测综述
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-11-14 13:43:00" itemprop="dateCreated datePublished" datetime="2020-11-14T13:43:00+08:00">2020-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-11-17 22:46:04" itemprop="dateModified" datetime="2020-11-17T22:46:04+08:00">2020-11-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index">
                    <span itemprop="name">计算机视觉</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>7.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>7 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <style type="text/css">
img{text-align: center; margin: 0 auto;width:80%;}
</style>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><blockquote>
<p>一转眼已经过去半年了，今年最大的愿望已经顺利实现！（有时间再专门开一篇文章专门记录保研之旅）<br>几经波折，总算是定好毕设题目啦！接下来是漫长的学习与实践道路，为了督促学习，开此坑来记录毕设学习全过程。</p>
</blockquote>
<p><strong><font color="#FF0000">本文记录了个人对于cv目标检测领域的知识点综述总结【Anchor-free待填坑】</font></strong></p>
<a id="more"></a>
<p>（PS：最近刚看了《大开眼戒》，分享一首曲子）</p>

    <div id="aplayer-lCJfCtuE" class="aplayer aplayer-tag-marker meting-tag-marker"
         data-id="26294503" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="true" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#ad7a86" data-loop="one" data-volume="0.7"
    ></div>


<h1 id="目标检测基础"><a href="#目标检测基础" class="headerlink" title="目标检测基础"></a>目标检测基础</h1><ol>
<li><em>任务定义</em><ul>
<li>输入：图像或者图像序列</li>
<li>输出：在每张/帧图像上，判断是否有指定类别的物体，如果有，给出所有物体的位置和大小（位置和大小可以用框图左上角坐标和长宽表示（x,y,w,h））<br><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-0.png" alt="玖涯博客"></li>
</ul>
</li>
<li><em>任务种类</em><ul>
<li>单类目标跟踪，多类/同用目标检测</li>
<li>静态图像目标检测，视频目标检测</li>
</ul>
</li>
<li><em>检测流程</em><ol>
<li><strong>生成候选区域</strong>：确定搜索范围<ul>
<li><strong>滑动窗口</strong>：滑动窗口本质上就是穷举法，利用不同的尺度和长宽比把所有可能的大大小小的块都穷举出来，然后送去识别，识别出来概率大的就留下来。很明显，这样的方法复杂度太高，产生了很多的冗余候选区域，在现实当中不可行。</li>
<li><strong>规则块</strong>：在穷举法的基础上进行了一些剪枝，只选用固定的大小和长宽比。这在一些特定的应用场景是很有效的，比如拍照搜题APP小猿搜题中的汉字检测，因为汉字方方正正，长宽比大多比较一致，因此用规则块做区域提名是一种比较合适的选择。但是对于普通的目标检测来说，规则块依然需要访问很多的位置，复杂度高。</li>
<li><strong>选择性搜索</strong>：从机器学习的角度来说，前面的方法召回是不错了，但是精度差强人意，所以问题的核心在于如何有效地去除冗余候选区域。其实冗余候选区域大多是发生了重叠，选择性搜索利用这一点，自底向上合并相邻的重叠区域，从而减少冗余。</li>
</ul>
</li>
<li><strong>提取区域特征</strong>：将候选区域表示为定长向量（由于分类器需要相同大小相同长度的向量作为输入）</li>
<li><strong>对区域进行分类</strong>：确定是否包含物体及其所属的类别</li>
<li><strong>后处理</strong>：对重叠较多的框进行合并（希望同一个物体上只有一个检测框）</li>
</ol>
</li>
</ol>
<h1 id="目标检测的深度学习方法"><a href="#目标检测的深度学习方法" class="headerlink" title="目标检测的深度学习方法"></a>目标检测的深度学习方法</h1><blockquote>
<p>深度学习目标检测方法根据是否使用检测框，可以划分为两大类：</p>
<ol>
<li><strong>anchor-based</strong>【基于候选框的目标检测】</li>
<li><strong>anchor-free</strong>【不基于候选框的目标检测】</li>
</ol>
</blockquote>
<h2 id="Anchor-based方法"><a href="#Anchor-based方法" class="headerlink" title="Anchor-based方法"></a><font color=#0000FF>Anchor-based方法</font></h2><p>这一类别下，还可以具体细分为：</p>
<ol>
<li><strong>双阶段</strong>【R-CNN,Fast R-CNN,Faster R-CNN,SPPnet】</li>
<li><strong>单阶段</strong>【SSD, YOLO, YOLOv2，YOLOv3】</li>
</ol>
<h3 id="双阶段目标检测模型"><a href="#双阶段目标检测模型" class="headerlink" title="双阶段目标检测模型"></a>双阶段目标检测模型</h3><p><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-1.png" alt="玖涯博客"><br>其中，“两阶段”具体指的是：</p>
<blockquote>
<ol>
<li>生成可能包含物体的候选区域Region Proposal</li>
<li>对候选区域做进一步分类校准，得到最终的检测结果</li>
</ol>
</blockquote>
<p>这里主要以R-CNN为例进行讲解：</p>
<h4 id="Ⅰ-滑动窗口检测器"><a href="#Ⅰ-滑动窗口检测器" class="headerlink" title="Ⅰ.滑动窗口检测器"></a><em>Ⅰ.滑动窗口检测器</em></h4><p><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-2.png" alt="玖涯博客"><br>顾名思义，寻找候选区域最简单的方法，就是滑动窗口法：</p>
<blockquote>
<p>从左到右、从上到下滑动窗口，利用分类识别目标。为了在不同观察距离处检测不同的目标类型，我们使用不同大小和宽高比的窗口。<br>我们创建很多窗口来检测不同位置的不同目标。要提升性能，一个显而易见的办法就是减少窗口数量。</p>
</blockquote>
<p>伪代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> window <span class="keyword">in</span> windows </span><br><span class="line">    patch = get_patch(image, window) </span><br><span class="line">　　results = detector(patch)</span><br></pre></td></tr></table></figure>
<h4 id="Ⅱ-选择性搜索"><a href="#Ⅱ-选择性搜索" class="headerlink" title="Ⅱ.选择性搜索"></a><em>Ⅱ.选择性搜索</em></h4><p>【算法具体细节参见：<a href="https://www.cnblogs.com/zyly/p/9259392.html" target="_blank" rel="noopener">目标检测之选择性搜索-Selective Search</a>】</p>
<h5 id="①SS算法原理"><a href="#①SS算法原理" class="headerlink" title="①SS算法原理"></a>①SS算法原理</h5><p>我们不使用暴力方法，而是用<strong>候选区域方法（region proposal method）创建目标检测的感兴趣区域（ROI）</strong>。</p>
<p>Selective Search的诞生，需要考虑以下几个问题：</p>
<ol>
<li><strong>适应不同尺度</strong>：穷举搜索（Exhaustive Selective）通过改变窗口大小来适应物体的不同尺度，选择搜索（Selective Search）同样无法避免这个问题。算法采用了图像分割（Image Segmentation）以及使用一种层次算法（Hierarchical Algorithm）有效地解决了这个问题。</li>
<li><strong>多样化</strong>：单一的策略无法应对多种类别的图像。使用颜色（color）、纹理（texture）、大小（size）等多种策略对分割好的区域（region）进行合并。</li>
<li><strong>速度快</strong>：算法，就像功夫一样，唯快不破！</li>
</ol>
<blockquote>
<p><font color="#FF0000">在选择性搜索（selective search，SS）中，我们首先将每个像素作为一组，计算每一组的纹理，并将两个<strong>最接近的组</strong>结合起来(贪心策略)。但是为了避免单个区域吞噬其他区域，我们首先对较小的组进行分组。我们继续合并区域，直到所有区域都结合在一起。然后这其中每次产生的图像块包括合并的图像块我们都保存下来，这样就得到图像的分层表示</font></p>
</blockquote>
<p>下图第一行展示了如何使区域增长，第二行中的蓝色矩形代表合并过程中所有可能的 ROI。</p>
<p><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-3.png" alt="玖涯博客"></p>
<h5 id="②SS算法步骤"><a href="#②SS算法步骤" class="headerlink" title="②SS算法步骤"></a>②SS算法步骤</h5><p>选择性搜索具体算法步骤如下：</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">输入: 一张图片</span><br><span class="line">输出：候选的目标位置集合L</span><br><span class="line"></span><br><span class="line">算法：</span><br><span class="line"><span class="number">1</span>: 利用切分方法得到候选的区域集合R = &#123;r1,r2,…,rn&#125;</span><br><span class="line"><span class="number">2</span>: 初始化相似集合S = ϕ</span><br><span class="line"><span class="number">3</span>: foreach 遍历邻居区域对(ri,rj) <span class="keyword">do</span></span><br><span class="line"><span class="number">4</span>:     计算相似度s(ri,rj)</span><br><span class="line"><span class="number">5</span>:     S = S  ∪ s(ri,rj)</span><br><span class="line"><span class="number">6</span>: <span class="keyword">while</span> S <span class="keyword">not</span>=ϕ <span class="keyword">do</span></span><br><span class="line"><span class="number">7</span>:     从S中得到最大的相似度s(ri,rj)=max(S)</span><br><span class="line"><span class="number">8</span>:     合并对应的区域rt = ri ∪ rj</span><br><span class="line"><span class="number">9</span>:     移除ri对应的所有相似度：S = S\s(ri,r*)</span><br><span class="line"><span class="number">10</span>:    移除rj对应的所有相似度：S = S\s(r*,rj)</span><br><span class="line"><span class="number">11</span>:    计算rt对应的相似度集合St</span><br><span class="line"><span class="number">12</span>:    S = S ∪ St</span><br><span class="line"><span class="number">13</span>:    R = R ∪ rt</span><br><span class="line"><span class="number">14</span>: L = R中所有区域对应的边框</span><br></pre></td></tr></table></figure>
<h5 id="③保持多样性的策略"><a href="#③保持多样性的策略" class="headerlink" title="③保持多样性的策略"></a>③保持多样性的策略</h5><p>区域合并采用了多样性的策略，如果简单采用一种策略很容易错误合并不相似的区域，比如只考虑纹理时，不同颜色的区域很容易被误合并。选择性搜索采用<strong>三种多样性策略</strong>来增加候选区域以保证召回：</p>
<ul>
<li>多种颜色空间，考虑RGB、灰度、HSV及其变种等</li>
<li>多种相似度度量标准，既考虑颜色相似度，又考虑纹理、大小、重叠情况等。</li>
<li>通过改变阈值初始化原始区域，阈值越大，分割的区域越少。</li>
</ul>
<h4 id="Ⅲ-R-CNN"><a href="#Ⅲ-R-CNN" class="headerlink" title="Ⅲ.R-CNN"></a><em>Ⅲ.R-CNN</em></h4><blockquote>
<p>R-CNN分为四个部分：区域划分、特征提取、区域分类、边框回归</p>
<ul>
<li>区域划分：使用selective search算法画出2k个左右候选框，送入CNN</li>
<li>特征提取：使用imagenet上训练好的模型，进行finetune</li>
<li>区域分类：从头训练一个SVM分类器，对CNN出来的特征向量进行分类</li>
<li>边框回归：使用线性回归，对边框坐标进行精修</li>
</ul>
</blockquote>
<p>R-CNN 利用<strong>候选区域方法</strong>创建了约 2000 个 ROI。这些区域被转换为<strong>固定大小</strong>的图像，并分别馈送到卷积神经网络中（将原始图像根据ROI切割、reshape再送进CNN学习）。<font color=#0000FF>该网络架构后面会跟几个全连接层，以实现目标分类并提炼边界框。</font></p>
<p><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-4.png" alt="玖涯博客"><br><strong><font color=#FF0000>通过使用更少且更高质量的 ROI，R-CNN 要比滑动窗口方法更快速、更准确。</font></strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ROIs = region_proposal(image)</span><br><span class="line"><span class="keyword">for</span> ROI <span class="keyword">in</span> ROIs:</span><br><span class="line">    patch = get_patch(image, ROI) </span><br><span class="line">    results = detector(pach)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>边界框回归器</p>
<p>  如下图，使用回归方法将蓝色的原始边界框提炼为红色的：<br><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-5.png" alt="使用回归方法将蓝色的原始边界框提炼为红色的"></p>
</li>
</ul>
<h4 id="Ⅳ-Fast-R-CNN"><a href="#Ⅳ-Fast-R-CNN" class="headerlink" title="Ⅳ.Fast R-CNN"></a>Ⅳ.Fast R-CNN</h4><p>R-CNN 需要非常多的候选区域以提升准确度，但其实有很多区域是<strong>彼此重叠</strong>的，因此 R-CNN 的训练和推断速度非常慢。如果我们有 2000 个候选区域，且每一个都需要独立地馈送到 CNN 中，那么对于不同的 ROI，我们需要重复提取 2000 次特征。（<strong>R-CNN很多卷积运算是重复的</strong>）</p>
<p>此外，CNN 中的特征图以一种密集的方式表征空间特征，是否能直接使用特征图代替原图来检测目标？</p>
<blockquote>
<p><font color=#FF0000>Fast R-CNN 使用特征提取器（CNN）先提取整个图像的特征，而不是从头开始对每个图像块提取多次。然后，我们可以将创建候选区域的方法直接应用到提取到的特征图上。</font><br>例如，Fast R-CNN 选择了 VGG16 中的卷积层 conv5 输出的 Feture Map 来生成 ROI，这些关注区域随后会结合对应的特征图以裁剪为特征图块，并用于目标检测任务中。我们<strong>使用 ROI 池化将特征图块转换为固定的大小</strong>，并馈送到全连接层进行分类和定位。因为 Fast-RCNN 不会重复提取特征，因此它能显著地减少处理时间。</p>
</blockquote>
<p>如下图，Fast R-CNN将候选区域直接应用于特征图，并使用 ROI 池化将其转化为固定大小的特征图块：<br><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-7.png" alt="将候选区域直接应用于特征图，并使用 ROI 池化将其转化为固定大小的特征图块"></p>
<p><strong>以下是 Fast R-CNN 的流程图：</strong><br><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-8.png" alt="玖涯博客"><br>在下面的伪代码中，<strong>计算量巨大的特征提取过程从 For 循环中移出来了</strong>，因此速度得到显著提升。Fast R-CNN 的训练速度是 R-CNN 的 10 倍，推断速度是后者的 150 倍。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">feature_maps = process(image)</span><br><span class="line">ROIs = region_proposal(feature_maps)</span><br><span class="line"><span class="keyword">for</span> ROI <span class="keyword">in</span> ROIs:</span><br><span class="line">    patch = roi_pooling(feature_maps, ROI) </span><br><span class="line">    results = detector2(patch)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><font color=FF0000>Fast R-CNN 最重要的一点就是包含特征提取器、分类器和边界框回归器在内的整个网络能通过多任务损失函数进行端到端的训练，这种多任务损失即结合了分类损失和定位损失的方法，大大提升了模型准确度。</font></p>
</blockquote>
<h4 id="Ⅴ-Faster-R-CNN"><a href="#Ⅴ-Faster-R-CNN" class="headerlink" title="Ⅴ.Faster R-CNN"></a>Ⅴ.Faster R-CNN</h4><p>Fast R-CNN 依赖于外部候选区域方法，如选择性搜索。但这些算法在 CPU 上运行且速度很慢。在测试中，Fast R-CNN 需要 2.3 秒来进行预测，其中 2 秒用于生成 2000 个 ROI。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">feature_maps = process(image)</span><br><span class="line">ROIs = region_proposal(feature_maps) <span class="comment"># Expensive!</span></span><br><span class="line"><span class="keyword">for</span> ROI <span class="keyword">in</span> ROIs:</span><br><span class="line">    patch = roi_pooling(feature_maps, ROI) </span><br><span class="line">    results = detector2(patch)</span><br></pre></td></tr></table></figure>
<p>Faster R-CNN 采用与 Fast R-CNN 相同的设计，<strong>只是它用内部深层网络(RPN)代替了候选区域方法</strong>。新的候选区域网络（RPN）在生成 ROI 时效率更高，并且以每幅图像 10 毫秒的速度运行。</p>
<p><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-9.png" alt="玖涯博客"></p>
<h5 id="①候选区域网络（RPN）"><a href="#①候选区域网络（RPN）" class="headerlink" title="①候选区域网络（RPN）"></a>①候选区域网络（RPN）</h5><p><strong>候选区域网络（RPN）</strong>将第一个卷积网络的输出特征图作为输入。它在特征图上滑动一个 3×3 的卷积核，以使用卷积网络（如下所示的 ZF 网络）构建与类别无关的候选区域。其他深度网络（如 VGG 或 ResNet）可用于更全面的特征提取，但这需要以速度为代价。</p>
<p>ZF 网络最后会输出 256 个值，它们将馈送到两个独立的全连接层，以预测边界框和两个 objectness 分数，这两个 objectness 分数度量了边界框是否包含目标。我们其实可以使用回归器计算单个 objectness 分数，但为简洁起见，Faster R-CNN 使用只有两个类别的分类器：即<strong>带有目标的类别</strong>和<strong>不带有目标的类别</strong>。</p>
<p><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-10.png" alt="玖涯博客"></p>
<h4 id="Ⅵ-基于区域的全卷积神经网络（R-FCN）"><a href="#Ⅵ-基于区域的全卷积神经网络（R-FCN）" class="headerlink" title="Ⅵ.基于区域的全卷积神经网络（R-FCN）"></a>Ⅵ.基于区域的全卷积神经网络（R-FCN）</h4><p>设计目的：</p>
<blockquote>
<p>虽然Faster R-CNN把整个的检测过程集成到了一个可以end-to-end训练的网络，实现了大部分计算的共享，也极大的提高了检测速度。<strong>但是整个检测过程还是不够快，因为Faster R-CNN虽然使用了conv layers来共享特征提取，但是在RoI pooling提取每个RoI的feature map之后，要使用FC layer单独对每个RoI进行分类和回归</strong>，所以假设提取了128个RoI，那么就要使用FC layer进行128次的回归和分类，而且大家也都知道FC layer的计算量是非常大的，所以这部分的计算就拖慢了Faster R-CNN的检测速度。所以还需要更充分的共享计算才能再提高速度，因此文章中提出了使用全卷积网络(FCN, Fully Convolutional Network)来实现计算共享，提高速度。</p>
</blockquote>
<p>现在我们回顾一下所有问题。在 Faster R-CNN 中，检测器使用了多个全连接层进行预测。如果有 2000 个 ROI，那么成本非常高:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">feature_maps = process(image)</span><br><span class="line">ROIs = region_proposal(feature_maps)</span><br><span class="line"><span class="keyword">for</span> ROI <span class="keyword">in</span> ROIs</span><br><span class="line">    patch = roi_pooling(feature_maps, ROI)</span><br><span class="line">    class_scores, box = detector(patch)         <span class="comment"># Expensive!</span></span><br><span class="line">    class_probabilities = softmax(class_scores)</span><br></pre></td></tr></table></figure>
<p><strong><font color=FF0000>R-FCN 通过减少每个 ROI 所需的工作量实现加速（去掉了全连接层）</font></strong>。</p>
<p>上面基于区域的特征图与 ROI 是独立的，可以在每个 ROI 之外单独计算。剩下的工作就比较简单了，因此 R-FCN 的速度比 Faster R-CNN 快。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">feature_maps = process(image)</span><br><span class="line">ROIs = region_proposal(feature_maps)         </span><br><span class="line">score_maps = compute_score_map(feature_maps)</span><br><span class="line"><span class="keyword">for</span> ROI <span class="keyword">in</span> ROIs</span><br><span class="line">    V = region_roi_pool(score_maps, ROI)     </span><br><span class="line">    class_scores, box = average(V)                   <span class="comment"># Much simpler!</span></span><br><span class="line">    class_probabilities = softmax(class_scores)</span><br></pre></td></tr></table></figure>
<p>PS：具体多看看链接<a href="https://www.cnblogs.com/guoyaohua/p/8994246.html" target="_blank" rel="noopener">基于区域的全卷积神经网络（R-FCN）</a></p>
<h3 id="单阶段目标检测模型"><a href="#单阶段目标检测模型" class="headerlink" title="单阶段目标检测模型"></a>单阶段目标检测模型</h3><p>第二部分，将对单次目标检测器（包括 SSD、YOLO、YOLOv2、YOLOv3）进行综述。将分析 FPN 以理解多尺度特征图如何提高准确率，特别是小目标的检测，其在单次检测器中的检测效果通常很差。</p>
<p>然后将分析 Focal loss 和 RetinaNet，看看它们是如何解决训练过程中的类别不平衡问题的。</p>
<h4 id="Ⅰ-单次目标检测器"><a href="#Ⅰ-单次目标检测器" class="headerlink" title="Ⅰ.单次目标检测器"></a>Ⅰ.单次目标检测器</h4><p>Faster R-CNN 中，在分类器之后有一个专用的候选区域网络。基于区域的检测器是很准确的，但需要付出代价。Faster R-CNN 在 PASCAL VOC 2007 测试集上每秒处理 7 帧的图像（7 FPS）。和 R-FCN 类似，研究者通过减少每个 ROI 的工作量来精简流程。</p>
<p>作为替代，我们是否需要一个分离的候选区域步骤？我们可以直接在一个步骤内得到边界框和类别吗？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">feature_maps = process(image)</span><br><span class="line">results = detector3(feature_maps) <span class="comment"># No more separate step for ROIs</span></span><br></pre></td></tr></table></figure>
<p>让我们再看一下滑动窗口检测器。我们可以通过在特征图上滑动窗口来检测目标。对于不同的目标类型，我们使用不同的窗口类型。</p>
<p>以前的滑动窗口方法的致命错误在于使用窗口作为最终的边界框，这就需要非常多的形状来覆盖大部分目标。<strong>更有效的方法是将窗口当做初始猜想，这样我们就得到了从当前滑动窗口同时预测类别和边界框的检测器。</strong></p>
<p><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-11.png" alt="基于滑动窗口进行预测"></p>
<blockquote>
<p>这个概念和 Faster R-CNN 中的锚点很相似。然而，<strong>单次检测器会同时预测边界框和类别。</strong><br>例如：在 Faster R-CNN 中，我们使用卷积核来做 5 个参数的预测：4 个参数对应某个锚点的预测边框，1 个参数对应 objectness 置信度得分。在单次检测器中，卷积核还预测 C 个类别概率以执行分类（每个概率对应一个类别）。</p>
</blockquote>
<p><strong>单次检测器通常需要在准确率和实时处理速度之间进行权衡。它们在检测太近距离或太小的目标时容易出现问题。</strong></p>
<h4 id="Ⅱ-SSD-Single-Shot-MultiBox-Detector"><a href="#Ⅱ-SSD-Single-Shot-MultiBox-Detector" class="headerlink" title="Ⅱ.SSD(Single Shot MultiBox Detector)"></a>Ⅱ.SSD(Single Shot MultiBox Detector)</h4><p>SSD 是使用 VGG19 网络作为特征提取器（和 Faster R-CNN 中使用的 CNN 一样）的单次检测器。我们在该网络之后添加自定义卷积层（蓝色），并使用卷积核（绿色）执行预测。</p>
<p><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-12.png" alt="同时对类别和位置执行单次预测"><br><strong><font color=#FF0000>然而，卷积层降低了空间维度和分辨率。因此上述模型仅可以检测较大的目标。为了解决该问题，我们从多个特征图上执行独立的目标检测。采用多尺度特征图独立检测，如下图：</font></strong></p>
<p><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-13.png" alt="使用多尺度特征图用于检测"></p>
<p><strong>SSD 使用卷积网络中较深的层来检测目标</strong>。如果我们按接近真实的比例重绘图像，我们会发现图像的空间分辨率已经被显著降低，且可能已无法定位在低分辨率中难以检测的小目标。如果出现了这样的问题，我们需要增加输入图像的分辨率。</p>
<h4 id="Ⅲ-YOLO"><a href="#Ⅲ-YOLO" class="headerlink" title="Ⅲ.YOLO"></a>Ⅲ.YOLO</h4><blockquote>
<p>准确地说，Yolo算法一共有三个版本，<strong>YoloV1可以算作anchor-free类</strong>；YoloV2开始引入anchor，因此<strong>YoloV2和YoloV3算作anchor-based类</strong>。<br><strong><font color=#FF0000>YOLO</font></strong>在卷积层之后使用了 DarkNet 来做特征检测。</p>
</blockquote>
<p><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-14.png" alt="玖涯博客"><br><strong>然而，它并没有使用多尺度特征图来做独立的检测。相反，它将特征图部分平滑化，并将其和另一个较低分辨率的特征图拼接。</strong>例如，YOLO 将一个 28 × 28 × 512 的层重塑为 14 × 14 × 2048，然后将它和 14 × 14 ×1024 的特征图拼接。之后，YOLO 在新的 14 × 14 × 3072 层上应用卷积核进行预测。</p>
<blockquote>
<p><strong><font color=#FF0000>YOLOv2（YOLO9000）</font></strong>做出了很多实现上的改进，可以检测 9000 种不同类别的目标。</p>
</blockquote>
<blockquote>
<p><strong><font color=#FF0000>YOLOv3</font></strong>使用了更加复杂的骨干网络来提取特征。DarkNet-53 主要由 3 × 3 和 1× 1 的卷积核以及类似 ResNet 中的跳过连接构成。<strong>YOLOv3 还添加了特征金字塔，以更好地检测小目标</strong></p>
</blockquote>
<h5 id="①特征金字塔网络（FPN）"><a href="#①特征金字塔网络（FPN）" class="headerlink" title="①特征金字塔网络（FPN）"></a>①特征金字塔网络（FPN）</h5><p>检测不同尺度的目标很有挑战性，尤其是小目标的检测。<strong>特征金字塔网络（FPN）是一种旨在提高准确率和速度的特征提取器。</strong>它取代了检测器（如 Faster R-CNN）中的特征提取器，并生成更高质量的特征图金字塔。FPN结构如下【个人感觉和U-Net很像】：<br><img src="/2020/11/14/%E6%AF%95%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC/pasted-15.png" alt="玖涯博客"></p>
<p>FPN 由<strong>自下而上和自上而下</strong>路径组成：</p>
<ul>
<li>其中<strong>自下而上的路径（上图左侧）</strong>是用于特征提取的常用卷积网络。空间分辨率自下而上地下降。当检测到更高层的结构，每层的语义值增加。</li>
<li>同时，FPN 提供了一条<strong>自上而下的路径（上图右侧）</strong>，从语义丰富的层构建高分辨率的层。重建层的语义较强，但在经过所有的上采样和下采样之后，目标的位置不精确。在重建层和相应的特征图之间添加横向连接可以使位置侦测更加准确。</li>
</ul>
<hr>
<h2 id="Anchor-free方法"><a href="#Anchor-free方法" class="headerlink" title="Anchor-free方法"></a><font color=#0000FF>Anchor-free方法</font></h2><p>关于anchor-free方法，首先是之前没有太多的接触，翻看了很多帖子发现都看不太懂（有点深奥？），更多的细节之后再来补充，先记录一些宏观性的比较，了解一下大体上的区别。</p>
<h3 id="anchor-free与anchor-based的区别"><a href="#anchor-free与anchor-based的区别" class="headerlink" title="anchor-free与anchor-based的区别"></a>anchor-free与anchor-based的区别</h3><p>这个问题首先需要回答为什么要有 anchor。在深度学习时代，物体检测问题通常都被建模成对一些候选区域进行分类和回归的问题：</p>
<ul>
<li>在单阶段检测器中，这些候选区域就是通过滑窗方式产生的 anchor；</li>
<li>在两阶段检测器中，候选区域是 RPN 生成的 proposal，但是 RPN 本身仍然是对滑窗方式产生的 anchor 进行分类和回归。</li>
</ul>
<p>而在 anchor-free 方法中，是通过另外一种手段来解决检测问题的。同样分为两个子问题，即<strong><font color=#FF0000>确定物体中心</font></strong>和<strong><font color=#FF0000>对四条边框的预测</font></strong>。预测物体中心时，具体实现既可以<u>定义一个 hard 的中心区域，将中心预测融入到类别预测的 target 里面</u>，也可以<u>预测一个 soft 的 centerness score</u>。对于四条边框的预测，则比较一致，都是预测该像素点到 ground truth 框的四条边距离，不过会使用一些 trick 来限制 regress 的范围。</p>
<h3 id="anchor-free类算法归纳"><a href="#anchor-free类算法归纳" class="headerlink" title="anchor-free类算法归纳"></a>anchor-free类算法归纳</h3><ol>
<li>基于多关键点联合表达的方法<ul>
<li>CornerNet/CornerNet-lite：左上角点+右下角点</li>
<li>ExtremeNet：上下左右4个极值点+中心点</li>
<li>CenterNet：Keypoint Triplets for Object Detection：左上角点+右下角点+中心点</li>
<li>RepPoints：9个学习到的自适应跳动的采样点e.FoveaBox：中心点+左上角点+右下角点</li>
<li>PLN：4个角点+中心点</li>
</ul>
</li>
<li>基于单中心点预测的方法<ul>
<li>CenterNet：Objects as Points：中心点+宽度+高度</li>
<li>CSP：中心点+高度（作者预设了目标宽高比固定，根据高度计算出宽度）</li>
<li>FCOS：中心点+到框的2个距离</li>
</ul>
</li>
</ol>

    </div>

    
    
    
        <div class="reward-container">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="PM 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="PM 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/" rel="tag"># 毕业设计</a>
              <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag"># 目标检测</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/05/04/ix2pix%E9%A1%B9%E7%9B%AE%EF%BC%88Keras%EF%BC%89%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E6%AD%A5%E9%AA%A4%E6%8C%87%E5%AF%BC%E8%AF%B4%E6%98%8E/" rel="prev" title="Pix2pix项目（Keras）环境配置步骤指导说明">
      <i class="fa fa-chevron-left"></i> Pix2pix项目（Keras）环境配置步骤指导说明
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/11/17/%E8%AE%BE%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85-2-%E7%89%B9%E5%BE%81%E9%87%91%E5%AD%97%E5%A1%94%EF%BC%9AFPN/" rel="next" title="毕设学习之旅-2.FPN（特征金字塔）">
      毕设学习之旅-2.FPN（特征金字塔） <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#前言"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#目标检测基础"><span class="nav-number">2.</span> <span class="nav-text">目标检测基础</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#目标检测的深度学习方法"><span class="nav-number">3.</span> <span class="nav-text">目标检测的深度学习方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Anchor-based方法"><span class="nav-number">3.1.</span> <span class="nav-text">Anchor-based方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#双阶段目标检测模型"><span class="nav-number">3.1.1.</span> <span class="nav-text">双阶段目标检测模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Ⅰ-滑动窗口检测器"><span class="nav-number">3.1.1.1.</span> <span class="nav-text">Ⅰ.滑动窗口检测器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Ⅱ-选择性搜索"><span class="nav-number">3.1.1.2.</span> <span class="nav-text">Ⅱ.选择性搜索</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#①SS算法原理"><span class="nav-number">3.1.1.2.1.</span> <span class="nav-text">①SS算法原理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#②SS算法步骤"><span class="nav-number">3.1.1.2.2.</span> <span class="nav-text">②SS算法步骤</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#③保持多样性的策略"><span class="nav-number">3.1.1.2.3.</span> <span class="nav-text">③保持多样性的策略</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Ⅲ-R-CNN"><span class="nav-number">3.1.1.3.</span> <span class="nav-text">Ⅲ.R-CNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Ⅳ-Fast-R-CNN"><span class="nav-number">3.1.1.4.</span> <span class="nav-text">Ⅳ.Fast R-CNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Ⅴ-Faster-R-CNN"><span class="nav-number">3.1.1.5.</span> <span class="nav-text">Ⅴ.Faster R-CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#①候选区域网络（RPN）"><span class="nav-number">3.1.1.5.1.</span> <span class="nav-text">①候选区域网络（RPN）</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Ⅵ-基于区域的全卷积神经网络（R-FCN）"><span class="nav-number">3.1.1.6.</span> <span class="nav-text">Ⅵ.基于区域的全卷积神经网络（R-FCN）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#单阶段目标检测模型"><span class="nav-number">3.1.2.</span> <span class="nav-text">单阶段目标检测模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Ⅰ-单次目标检测器"><span class="nav-number">3.1.2.1.</span> <span class="nav-text">Ⅰ.单次目标检测器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Ⅱ-SSD-Single-Shot-MultiBox-Detector"><span class="nav-number">3.1.2.2.</span> <span class="nav-text">Ⅱ.SSD(Single Shot MultiBox Detector)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Ⅲ-YOLO"><span class="nav-number">3.1.2.3.</span> <span class="nav-text">Ⅲ.YOLO</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#①特征金字塔网络（FPN）"><span class="nav-number">3.1.2.3.1.</span> <span class="nav-text">①特征金字塔网络（FPN）</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Anchor-free方法"><span class="nav-number">3.2.</span> <span class="nav-text">Anchor-free方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#anchor-free与anchor-based的区别"><span class="nav-number">3.2.1.</span> <span class="nav-text">anchor-free与anchor-based的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#anchor-free类算法归纳"><span class="nav-number">3.2.2.</span> <span class="nav-text">anchor-free类算法归纳</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="PM"
      src="/images/headImage.jpeg">
  <p class="site-author-name" itemprop="name">PM</p>
  <div class="site-description" itemprop="description">菜鸡博客,记录生活</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">18</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="sidebar-button motion-element">
    <a onclick="tidioChatApi.open();"><i class="fa fa-comment"></i>
    Chat
  </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/GKNL" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;GKNL" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/p/1005055407797948" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;p&#x2F;1005055407797948" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.douban.com/people/174736231" title="豆瓣 → https:&#x2F;&#x2F;www.douban.com&#x2F;people&#x2F;174736231" rel="noopener" target="_blank"><i class="fa fa-fw fa-film"></i>豆瓣</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PM</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">48k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">44 分钟</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.7.0
  </div>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>






  <script src="//code.tidio.co/f3sywhcpt4zyg236jgrfp0lip9hatdlc.js"></script>







  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el: '#valine-comments',
      verify: false,
      notify: false,
      appId: 'mVCwf8GoBdypxm3OvgECOoTX-gzGzoHsz',
      appKey: 'OvvQXJ2N7WL2df5pMrOyVNLC',
      placeholder: "Please comment here ^_^",
      avatar: 'mm',
      meta: guest,
      pageSize: '10' || 10,
      visitor: false,
      lang: '' || 'zh-cn',
      path: location.pathname,
      recordIP: false,
      serverURLs: ''
    });
  }, window.Valine);
});
</script>

  
	<!-- weather -->
	<script type="text/javascript">
	WIDGET = {FID: 'jvFer2ULXH'}
	</script>
	<script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>
</body>
</html>
